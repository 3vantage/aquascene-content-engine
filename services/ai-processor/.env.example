# AI Content Processor Environment Configuration

# Server Configuration
HOST=0.0.0.0
PORT=8001
DEBUG=false
ENVIRONMENT=development

# LLM API Keys
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Ollama Configuration (for local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODELS=llama3.1:8b,mistral:7b

# Database Configuration
DATABASE_URL=postgresql://user:password@localhost:5432/content_engine
REDIS_URL=redis://localhost:6379

# Content Generation Settings
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2000
DEFAULT_TIMEOUT_SECONDS=30

# Batch Processing Settings
MAX_CONCURRENT_REQUESTS=5
BATCH_PROCESSING_TIMEOUT=3600
MAX_BATCH_SIZE=100

# Rate Limiting
REQUESTS_PER_MINUTE_LIMIT=100
BURST_LIMIT=20

# Template Directories (comma-separated)
TEMPLATE_DIRECTORIES=templates,../distributor/templates

# Knowledge Base
KNOWLEDGE_BASE_DIRECTORY=data/knowledge

# Logging and Monitoring
LOG_LEVEL=INFO
STRUCTURED_LOGGING=true
SENTRY_DSN=your_sentry_dsn_here

# Metrics
ENABLE_METRICS=true
METRICS_PORT=9090
HEALTH_CHECK_INTERVAL=30

# Resource Management
MAX_MEMORY_USAGE_PERCENT=80.0
MAX_CPU_USAGE_PERCENT=90.0
MAX_ACTIVE_JOBS=10

# Security
API_KEY=your_api_key_here
ALLOWED_ORIGINS=*

# Content Optimization
ENABLE_SEO_OPTIMIZATION=true
ENABLE_ENGAGEMENT_OPTIMIZATION=true
ENABLE_SOCIAL_OPTIMIZATION=true

# Brand Settings
BRAND_VOICE=professional and educational
TARGET_AUDIENCE=aquascaping enthusiasts
COMPANY_NAME=AquaScene

# Storage
CONTENT_STORAGE_DIRECTORY=data/content
MAX_FILE_SIZE_MB=10

# Cache Settings
ENABLE_CACHING=true
CACHE_TTL_SECONDS=3600

# Development Settings
MOCK_LLM_RESPONSES=false
ENABLE_DEBUG_ENDPOINTS=false